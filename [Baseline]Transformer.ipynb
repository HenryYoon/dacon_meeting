{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "baseline.ipynb<br>\n",
    ".. └ data<br>\n",
    ".... ├ train.json<br>\n",
    ".... ├ test.json<br>\n",
    ".... └ sample_submission.csv<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 사용 패키지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "import copy\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 랜덤 시드 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)  # type: ignore\n",
    "    torch.backends.cudnn.deterministic = True  # type: ignore\n",
    "    torch.backends.cudnn.benchmark = True  # type: ignore\n",
    "\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR = \"./data\"\n",
    "TRAIN_SOURCE = os.path.join(DIR, \"train.json\")\n",
    "TEST_SOURCE = os.path.join(DIR, \"test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(TRAIN_SOURCE) as f:\n",
    "    TRAIN_DATA = json.loads(f.read())\n",
    "    \n",
    "with open(TEST_SOURCE) as f:\n",
    "    TEST_DATA = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.DataFrame(columns=['uid', 'title', 'region', 'context', 'summary'])\n",
    "uid = 1000\n",
    "for data in TRAIN_DATA:\n",
    "    for agenda in data['context'].keys():\n",
    "        context = ''\n",
    "        for line in data['context'][agenda]:\n",
    "            context += data['context'][agenda][line]\n",
    "            context += ' '\n",
    "        train.loc[uid, 'uid'] = uid\n",
    "        train.loc[uid, 'title'] = data['title']\n",
    "        train.loc[uid, 'region'] = data['region']\n",
    "        train.loc[uid, 'context'] = context[:-1]\n",
    "        train.loc[uid, 'summary'] = data['label'][agenda]['summary']\n",
    "        uid += 1\n",
    "\n",
    "test = pd.DataFrame(columns=['uid', 'title', 'region', 'context'])\n",
    "uid = 2000\n",
    "for data in TEST_DATA:\n",
    "    for agenda in data['context'].keys():\n",
    "        context = ''\n",
    "        for line in data['context'][agenda]:\n",
    "            context += data['context'][agenda][line]\n",
    "            context += ' '\n",
    "        test.loc[uid, 'uid'] = uid\n",
    "        test.loc[uid, 'title'] = data['title']\n",
    "        test.loc[uid, 'region'] = data['region']\n",
    "        test.loc[uid, 'context'] = context[:-1]\n",
    "        uid += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['total'] = train.title + ' ' + train.region + ' ' + train.context\n",
    "test['total'] = test.title + ' ' + test.region + ' ' + test.context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>title</th>\n",
       "      <th>region</th>\n",
       "      <th>context</th>\n",
       "      <th>summary</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>1000</td>\n",
       "      <td>제207회 완주군의회(임시회) 제 1 차 본회의회의록</td>\n",
       "      <td>완주</td>\n",
       "      <td>의석을 정돈하여 주시기 바랍니다. 성원이 되었으므로 제207회 완주군의회 임시회 제...</td>\n",
       "      <td>제207회 완주군의회 임시회 제1차 본회의 개의 선포.</td>\n",
       "      <td>제207회 완주군의회(임시회) 제 1 차 본회의회의록 완주 의석을 정돈하여 주시기 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>1001</td>\n",
       "      <td>제207회 완주군의회(임시회) 제 1 차 본회의회의록</td>\n",
       "      <td>완주</td>\n",
       "      <td>의사팀장 수고하셨습니다. 먼저 의사일정 제1항 제207회 완주군의회 임시회 회기 결...</td>\n",
       "      <td>제207회 완주군의회 임시회 회기는 8월 26일부터 9월 4일까지 10일간으로 가결됨.</td>\n",
       "      <td>제207회 완주군의회(임시회) 제 1 차 본회의회의록 완주 의사팀장 수고하셨습니다....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>1002</td>\n",
       "      <td>제207회 완주군의회(임시회) 제 1 차 본회의회의록</td>\n",
       "      <td>완주</td>\n",
       "      <td>다음은 의사일정 제2항 제207회 완주군의회 임시회 회의록 서명의원 선출의 건을 상...</td>\n",
       "      <td>제207회 완주군의회 임시회 회의록 서명의원으로 최등원 의원과 박웅배 의원이 선출됨.</td>\n",
       "      <td>제207회 완주군의회(임시회) 제 1 차 본회의회의록 완주 다음은 의사일정 제2항 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>1003</td>\n",
       "      <td>제207회 완주군의회(임시회) 제 1 차 본회의회의록</td>\n",
       "      <td>완주</td>\n",
       "      <td>다음은 의사일정 제3항 본회의 휴회의 건을 상정합니다. 상임의원회 의정활동을 위하여...</td>\n",
       "      <td>8월 27일부터 9월 3일까지 8일간 휴회가 가결됨. 제2차 본회의는 9월 4일 오...</td>\n",
       "      <td>제207회 완주군의회(임시회) 제 1 차 본회의회의록 완주 다음은 의사일정 제3항 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>1004</td>\n",
       "      <td>제251회 완주군의회(제1차 정례회) 제1차 본 회 의 회 의 록</td>\n",
       "      <td>완주</td>\n",
       "      <td>의석을 정돈하여 주시기 바랍니다. 성원이 되었으므로 제251회 완주군의회 제1차 정...</td>\n",
       "      <td>제251회 완주군의회 제1차 정례회 제1차 본회의 개의 선포.</td>\n",
       "      <td>제251회 완주군의회(제1차 정례회) 제1차 본 회 의 회 의 록 완주 의석을 정돈...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       uid                                 title region  \\\n",
       "1000  1000         제207회 완주군의회(임시회) 제 1 차 본회의회의록     완주   \n",
       "1001  1001         제207회 완주군의회(임시회) 제 1 차 본회의회의록     완주   \n",
       "1002  1002         제207회 완주군의회(임시회) 제 1 차 본회의회의록     완주   \n",
       "1003  1003         제207회 완주군의회(임시회) 제 1 차 본회의회의록     완주   \n",
       "1004  1004  제251회 완주군의회(제1차 정례회) 제1차 본 회 의 회 의 록     완주   \n",
       "\n",
       "                                                context  \\\n",
       "1000  의석을 정돈하여 주시기 바랍니다. 성원이 되었으므로 제207회 완주군의회 임시회 제...   \n",
       "1001  의사팀장 수고하셨습니다. 먼저 의사일정 제1항 제207회 완주군의회 임시회 회기 결...   \n",
       "1002  다음은 의사일정 제2항 제207회 완주군의회 임시회 회의록 서명의원 선출의 건을 상...   \n",
       "1003  다음은 의사일정 제3항 본회의 휴회의 건을 상정합니다. 상임의원회 의정활동을 위하여...   \n",
       "1004  의석을 정돈하여 주시기 바랍니다. 성원이 되었으므로 제251회 완주군의회 제1차 정...   \n",
       "\n",
       "                                                summary  \\\n",
       "1000                     제207회 완주군의회 임시회 제1차 본회의 개의 선포.   \n",
       "1001   제207회 완주군의회 임시회 회기는 8월 26일부터 9월 4일까지 10일간으로 가결됨.   \n",
       "1002    제207회 완주군의회 임시회 회의록 서명의원으로 최등원 의원과 박웅배 의원이 선출됨.   \n",
       "1003  8월 27일부터 9월 3일까지 8일간 휴회가 가결됨. 제2차 본회의는 9월 4일 오...   \n",
       "1004                 제251회 완주군의회 제1차 정례회 제1차 본회의 개의 선포.   \n",
       "\n",
       "                                                  total  \n",
       "1000  제207회 완주군의회(임시회) 제 1 차 본회의회의록 완주 의석을 정돈하여 주시기 ...  \n",
       "1001  제207회 완주군의회(임시회) 제 1 차 본회의회의록 완주 의사팀장 수고하셨습니다....  \n",
       "1002  제207회 완주군의회(임시회) 제 1 차 본회의회의록 완주 다음은 의사일정 제2항 ...  \n",
       "1003  제207회 완주군의회(임시회) 제 1 차 본회의회의록 완주 다음은 의사일정 제3항 ...  \n",
       "1004  제251회 완주군의회(제1차 정례회) 제1차 본 회 의 회 의 록 완주 의석을 정돈...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>title</th>\n",
       "      <th>region</th>\n",
       "      <th>context</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>2000</td>\n",
       "      <td>제235회    본회의 제1차(2012.06.21.)</td>\n",
       "      <td>음성</td>\n",
       "      <td>의석을 정돈하여 주시기 바랍니다. 성원이 되었으므로 지금부터 음성군의회 제235회 ...</td>\n",
       "      <td>제235회    본회의 제1차(2012.06.21.) 음성 의석을 정돈하여 주시기 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>2001</td>\n",
       "      <td>제235회    본회의 제1차(2012.06.21.)</td>\n",
       "      <td>음성</td>\n",
       "      <td>의사일정 제1항, 음성군의회 제235회 제1차 정례회 회기결정의 건을 상정합니다. ...</td>\n",
       "      <td>제235회    본회의 제1차(2012.06.21.) 음성 의사일정 제1항, 음성군...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>2002</td>\n",
       "      <td>제235회    본회의 제1차(2012.06.21.)</td>\n",
       "      <td>음성</td>\n",
       "      <td>의사일정 제2항, 회의록 서명의원 선출의 건을 상정합니다. 제235회 제1차 정례회...</td>\n",
       "      <td>제235회    본회의 제1차(2012.06.21.) 음성 의사일정 제2항, 회의록...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>2003</td>\n",
       "      <td>제235회    본회의 제1차(2012.06.21.)</td>\n",
       "      <td>음성</td>\n",
       "      <td>의사일정 제3항, 예산결산특별위원회 구성의 건을 상정합니다. 예산결산특별위원회 구성...</td>\n",
       "      <td>제235회    본회의 제1차(2012.06.21.) 음성 의사일정 제3항, 예산결...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>2004</td>\n",
       "      <td>제235회    본회의 제1차(2012.06.21.)</td>\n",
       "      <td>음성</td>\n",
       "      <td>의사일정 제4항, 환경분야 현지확인 특별위원회 구성결의안을 상정합니다. 대표발의하신...</td>\n",
       "      <td>제235회    본회의 제1차(2012.06.21.) 음성 의사일정 제4항, 환경분...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       uid                          title region  \\\n",
       "2000  2000  제235회    본회의 제1차(2012.06.21.)     음성   \n",
       "2001  2001  제235회    본회의 제1차(2012.06.21.)     음성   \n",
       "2002  2002  제235회    본회의 제1차(2012.06.21.)     음성   \n",
       "2003  2003  제235회    본회의 제1차(2012.06.21.)     음성   \n",
       "2004  2004  제235회    본회의 제1차(2012.06.21.)     음성   \n",
       "\n",
       "                                                context  \\\n",
       "2000  의석을 정돈하여 주시기 바랍니다. 성원이 되었으므로 지금부터 음성군의회 제235회 ...   \n",
       "2001  의사일정 제1항, 음성군의회 제235회 제1차 정례회 회기결정의 건을 상정합니다. ...   \n",
       "2002  의사일정 제2항, 회의록 서명의원 선출의 건을 상정합니다. 제235회 제1차 정례회...   \n",
       "2003  의사일정 제3항, 예산결산특별위원회 구성의 건을 상정합니다. 예산결산특별위원회 구성...   \n",
       "2004  의사일정 제4항, 환경분야 현지확인 특별위원회 구성결의안을 상정합니다. 대표발의하신...   \n",
       "\n",
       "                                                  total  \n",
       "2000  제235회    본회의 제1차(2012.06.21.) 음성 의석을 정돈하여 주시기 ...  \n",
       "2001  제235회    본회의 제1차(2012.06.21.) 음성 의사일정 제1항, 음성군...  \n",
       "2002  제235회    본회의 제1차(2012.06.21.) 음성 의사일정 제2항, 회의록...  \n",
       "2003  제235회    본회의 제1차(2012.06.21.) 음성 의사일정 제3항, 예산결...  \n",
       "2004  제235회    본회의 제1차(2012.06.21.) 음성 의사일정 제4항, 환경분...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 5)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 하이퍼파라미터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_len = 500\n",
    "decoder_len = 50\n",
    "max_vocab_size = 20000\n",
    "batch_size = 32\n",
    "num_layers = 6\n",
    "d_model = 512\n",
    "dff = 2048\n",
    "num_heads = 8\n",
    "dropout_rate = 0.1\n",
    "epochs = 20\n",
    "learning_rate = 1e-4\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train, validation 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = train.iloc[:-200]\n",
    "df_val = train.iloc[-200:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 토크나이징"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mecab_Tokenizer():\n",
    "    def __init__(self, max_length, mode, max_vocab_size=-1):\n",
    "        self.text_tokenizer = Mecab()\n",
    "        self.mode = mode\n",
    "        self.txt2idx = {'pad_':0, 'unk_':1}\n",
    "        self.idx2txt = {0:'pad_', 1:'unk_'}\n",
    "        self.max_length = max_length\n",
    "        self.word_count = {}\n",
    "        self.max_vocab_size = max_vocab_size\n",
    "        \n",
    "        # 띄어쓰기를 찾기 위한 태그 목록\n",
    "        self.font_blank_tag = [\n",
    "            '', 'EC', 'EC+JKO', 'EF', 'EP+EC', 'EP+EP+EC', 'EP+ETM', 'EP+ETN+JKO', 'ETM', 'ETN', 'ETN+JKO', 'ETN+JX', 'IC', 'JC', 'JKB', 'JKB+JX', 'JKO',\n",
    "            'JKQ', 'JKS', 'JX', 'MAG', 'MAG+JX', 'MAG+XSV+EP+EC', 'MAJ','MM', 'MM+EC', 'NNB', 'NNB+JKB', 'NNB+JKO', 'NNB+VCP+EC', 'NNBC', 'NNG', 'NNG+JX+JKO',\n",
    "            'NNG+VCP+EC', 'NNP', 'NNP+JX', 'NP', 'NP+JKO', 'NP+JKS', 'NP+JX', 'NP+VCP+EC', 'NR', 'SC', 'SF', 'SL', 'SN', 'SSC', 'SSO', 'SY', 'UNKNOWN',\n",
    "            'VA+EC', 'VA+EC+VX+ETM', 'VA+ETM', 'VA+ETN+JKB+JX', 'VCN+EC', 'VCN+ETM', 'VCP', 'VCP+EC', 'VCP+EP+EC', 'VCP+EP+ETM', 'VCP+ETM', 'VCP+ETN',\n",
    "            'VV+EC', 'VV+EC+JX', 'VV+EC+VX+EC', 'VV+EC+VX+ETM', 'VV+EP+EC', 'VV+EP+ETM', 'VV+ETM', 'VV+ETN', 'VX+EC', 'VX+EC+VX+EP+EC', 'VX+EP+ETM',\n",
    "            'VX+ETM', 'XPN', 'XR', 'XSA+EC', 'XSA+EC+VX+ETM', 'XSA+ETM', 'XSN', 'XSV+EC', 'XSV+EP+EC', 'XSV+ETM', 'XSV+ETN', 'XSV+JKO'\n",
    "        ]\n",
    "        self.back_blank_tag = [\n",
    "            '', 'IC', 'MAG', 'MAG+JX', 'MAG+XSV+EP+EC', 'MAJ', 'MM', 'MM+EC', 'NNB', 'NNB+JKB', 'NNB+VCP', 'NNB+VCP+EC', 'NNB+VCP+EF', 'NNBC', 'NNBC+VCP+EC',\n",
    "            'NNG', 'NNG+JC', 'NNG+JX+JKO', 'NNG+VCP', 'NNG+VCP+EC', 'NNG+VCP+ETM', 'NNP', 'NNP+JX', 'NP', 'NP+JKG', 'NP+JKO', 'NP+JKS', 'NP+JX', 'NP+VCP+EC', 'NP+VCP+EF',\n",
    "            'NR', 'SC', 'SL', 'SN', 'SSC', 'SSO', 'SY', 'VA', 'VA+EC', 'VA+EC+VX+ETM', 'VA+EF', 'VA+ETM', 'VA+ETN', 'VA+ETN+JKB+JX', 'VCN', 'VCN+EC', 'VCN+EF', 'VCN+ETM',\n",
    "            'VCN+ETN', 'VCP', 'VCP+EF', 'VV', 'VV+EC', 'VV+EC+JX', 'VV+EC+VX', 'VV+EC+VX+EC', 'VV+EC+VX+EF', 'VV+EC+VX+EP+EC', 'VV+EC+VX+ETM', 'VV+EF', 'VV+EP', 'VV+EP+EC',\n",
    "            'VV+EP+ETM', 'VV+ETM', 'VV+ETN', 'VV+ETN+VCP+EF', 'VX', 'VX+ETM', 'XPN', 'XR', 'XSA+ETN+VCP+EF', 'XSN'\n",
    "        ]\n",
    "        \n",
    "    def morpheme(self, sentence_list):\n",
    "        new_sentence = []\n",
    "        for i, sentence in tqdm(enumerate(sentence_list)):\n",
    "            temp = []\n",
    "            if self.mode == 'dec':\n",
    "                temp.append('sos_')\n",
    "            for t in self.text_tokenizer.pos(sentence):\n",
    "                temp.append('_'.join(t))\n",
    "            if self.mode == 'dec':\n",
    "                temp.append('eos_')\n",
    "            new_sentence.append(' '.join(temp))\n",
    "            \n",
    "        return new_sentence\n",
    "    \n",
    "    def fit(self, sentence_list):\n",
    "        for sentence in tqdm(sentence_list):\n",
    "            for word in sentence.split(' '):\n",
    "                try:\n",
    "                    self.word_count[word] += 1\n",
    "                except:\n",
    "                    self.word_count[word] = 1\n",
    "        self.word_count = dict(sorted(self.word_count.items(), key=self.sort_target, reverse=True))\n",
    "        \n",
    "        self.txt2idx = {'pad_':0, 'unk_':1}\n",
    "        self.idx2txt = {0:'pad_', 1:'unk_'}\n",
    "        if self.max_vocab_size == -1:\n",
    "            for i, word in enumerate(list(self.word_count.keys())):\n",
    "                self.txt2idx[word]=i+2\n",
    "                self.idx2txt[i+2]=word\n",
    "        else:\n",
    "            for i, word in enumerate(list(self.word_count.keys())[:self.max_vocab_size]):\n",
    "                self.txt2idx[word]=i+2\n",
    "                self.idx2txt[i+2]=word\n",
    "        \n",
    "    def sort_target(self, x):\n",
    "        return x[1]\n",
    "            \n",
    "    def txt2token(self, sentence_list):\n",
    "        tokens = []\n",
    "        for sentence in tqdm(sentence_list):\n",
    "            token = [0]*self.max_length\n",
    "            for i, w in enumerate(sentence.split(' ')):\n",
    "                if i == self.max_length:\n",
    "                    break\n",
    "                try:\n",
    "                    token[i] = self.txt2idx[w]\n",
    "                except:\n",
    "                    token[i] = self.txt2idx['unk_']\n",
    "            tokens.append(token)\n",
    "        return np.array(tokens)\n",
    "    \n",
    "    def convert(self, token):\n",
    "        sentence = []\n",
    "        for j, i in enumerate(token):\n",
    "            if self.mode == 'enc':\n",
    "                if i != self.txt2idx['pad_']:\n",
    "                    sentence.append(self.idx2txt[i].split('_')[0])\n",
    "            elif self.mode == 'dec':\n",
    "                if i == self.txt2idx['eos_'] or i == self.txt2idx['pad_']:\n",
    "                    break\n",
    "                elif i != 0:\n",
    "                    sentence.append(self.idx2txt[i].split('_')[0])\n",
    "                    # 앞뒤 태그를 확인하여 띄어쓰기 추가\n",
    "                    if self.idx2txt[i].split('_')[1] in self.font_blank_tag:\n",
    "                        try:\n",
    "                            if self.idx2txt[token[j+1]].split('_')[1] in self.back_blank_tag:\n",
    "                                sentence.append(' ')\n",
    "                        except:\n",
    "                            pass\n",
    "        sentence = \"\".join(sentence)\n",
    "        if self.mode == 'enc':\n",
    "            sentence = sentence[:-1]\n",
    "        elif self.mode == 'dec':\n",
    "            sentence = sentence[3:-1]\n",
    "            \n",
    "        return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_tokenizer = Mecab_Tokenizer(encoder_len, mode='enc', max_vocab_size=max_vocab_size)\n",
    "tar_tokenizer = Mecab_Tokenizer(decoder_len, mode='dec', max_vocab_size=max_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2794it [00:12, 221.65it/s]\n",
      "200it [00:00, 355.38it/s]\n",
      "506it [00:01, 258.94it/s]\n",
      "2794it [00:00, 3230.08it/s]\n",
      "200it [00:00, 6728.43it/s]\n"
     ]
    }
   ],
   "source": [
    "train_src = src_tokenizer.morpheme(df_train.total)\n",
    "val_src = src_tokenizer.morpheme(df_val.total)\n",
    "test_src = src_tokenizer.morpheme(test.total)\n",
    "\n",
    "train_tar = tar_tokenizer.morpheme(df_train.summary)\n",
    "val_tar = tar_tokenizer.morpheme(df_val.summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_src_len = []\n",
    "# for m in train_src:\n",
    "#     m_len = len(m.split(' '))\n",
    "#     train_src_len.append(m_len)\n",
    "# print('train_src_max_len :', max(train_src_len))\n",
    "# plt.hist(train_src_len, bins=30)\n",
    "# plt.show()\n",
    "\n",
    "# train_tar_len = []\n",
    "# for m in train_tar:\n",
    "#     m_len = len(m.split(' '))\n",
    "#     train_tar_len.append(m_len)\n",
    "# print('train_tar_max_len :', max(train_tar_len))\n",
    "# plt.hist(train_tar_len, bins=30)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2794/2794 [00:00<00:00, 7017.87it/s]\n",
      "100%|██████████| 2794/2794 [00:00<00:00, 119662.27it/s]\n"
     ]
    }
   ],
   "source": [
    "src_tokenizer.fit(train_src)\n",
    "tar_tokenizer.fit(train_tar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2794/2794 [00:00<00:00, 10938.96it/s]\n",
      "100%|██████████| 200/200 [00:00<00:00, 7431.44it/s]\n",
      "100%|██████████| 506/506 [00:00<00:00, 10649.93it/s]\n",
      "100%|██████████| 2794/2794 [00:00<00:00, 119785.81it/s]\n",
      "100%|██████████| 200/200 [00:00<00:00, 99615.34it/s]\n"
     ]
    }
   ],
   "source": [
    "train_src_tokens = src_tokenizer.txt2token(train_src)\n",
    "val_src_tokens = src_tokenizer.txt2token(val_src)\n",
    "test_src_tokens = src_tokenizer.txt2token(test_src)\n",
    "\n",
    "train_tar_tokens = tar_tokenizer.txt2token(train_tar)\n",
    "val_tar_tokens = tar_tokenizer.txt2token(val_tar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_vocab_size = len(src_tokenizer.txt2idx)\n",
    "target_vocab_size = len(tar_tokenizer.txt2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20002, 4877)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_vocab_size, target_vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'제207회 완주군의회 임시회 제1차 본회의 개의 선포.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.summary.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   3,    8, 1131,   19,   42,   21,   24,    8,   35,   25,   49,\n",
       "           5,   44,    5,   52,    2,    4,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0]),\n",
       " ' 제 207 회 완주군 의회 임시회 제 1 차 본회의개의선포.')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tar_tokens[0], tar_tokenizer.convert(train_tar_tokens[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, src_tokens, tar_tokens, mode='train'):\n",
    "        self.mode = mode\n",
    "        self.src_tokens = src_tokens\n",
    "        if self.mode == 'train':\n",
    "            self.tar_tokens = tar_tokens\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.src_tokens)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        src_token = self.src_tokens[i]\n",
    "        if self.mode == 'train':\n",
    "            tar_token = self.tar_tokens[i]\n",
    "            return {\n",
    "                'src_token' : torch.tensor(src_token, dtype=torch.long),\n",
    "                'tar_token' : torch.tensor(tar_token, dtype=torch.long),\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                'src_token' : torch.tensor(src_token, dtype=torch.long)\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(train_src_tokens, train_tar_tokens)\n",
    "val_dataset = CustomDataset(val_src_tokens, val_tar_tokens)\n",
    "test_dataset = CustomDataset(test_src_tokens, None, 'test')\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, num_workers=1, shuffle=True)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, num_workers=1, shuffle=False)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, num_workers=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 Transformer\n",
    "\n",
    "https://www.tensorflow.org/text/tutorials/transformer 를 pytorch코드로 수정하여 작성하였습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "Dc7o26Txp_wh"
   },
   "outputs": [],
   "source": [
    "def get_angles(pos, i, d_model):\n",
    "    angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
    "    return pos * angle_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "K8l-XKICp_wi"
   },
   "outputs": [],
   "source": [
    "def positional_encoding(position, d_model):\n",
    "    angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
    "                            np.arange(d_model)[np.newaxis, :],\n",
    "                            d_model)\n",
    "\n",
    "    # apply sin to even indices in the array; 2i\n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "\n",
    "    # apply cos to odd indices in the array; 2i+1\n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    pos_encoding = angle_rads[np.newaxis, ...]\n",
    "\n",
    "    return torch.tensor(pos_encoding, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(seq):\n",
    "    seq = torch.tensor(torch.eq(seq, 0), dtype=torch.float32)\n",
    "\n",
    "    # add extra dimensions to add the padding\n",
    "    # to the attention logits.\n",
    "    seq = seq.unsqueeze(1).unsqueeze(2)\n",
    "    return seq  # (batch_size, 1, 1, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(size):\n",
    "    mask = torch.ones(size, size).triu(diagonal=1)\n",
    "    return mask  # (seq_len, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "MrkZ_SWsp_wi"
   },
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "    matmul_qk = torch.matmul(q, torch.transpose(k, -2, -1))  # (..., seq_len_q, seq_len_k)\n",
    "    \n",
    "    # scale matmul_qk\n",
    "    dk = k.size()[-1]\n",
    "    scaled_attention_logits = matmul_qk / math.sqrt(dk)\n",
    "    \n",
    "    # add the mask to the scaled tensor.\n",
    "    if mask is not None:\n",
    "        scaled_attention_logits += (mask * -1e9)\n",
    "\n",
    "    # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
    "    # add up to 1.\n",
    "    attention_weights = torch.nn.functional.softmax(scaled_attention_logits, dim=-1)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "    output = torch.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
    "\n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_out(q, k, v):\n",
    "    temp_out, temp_attn = scaled_dot_product_attention(\n",
    "      q, k, v, None)\n",
    "    print('Attention weights are:')\n",
    "    print(temp_attn)\n",
    "    print('Output is:')\n",
    "    print(temp_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights are:\n",
      "tensor([[8.4333e-26, 1.0000e+00, 8.4333e-26, 8.4333e-26]])\n",
      "Output is:\n",
      "tensor([[1.0000e+01, 9.2766e-25]])\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "temp_k = torch.tensor([[10, 0, 0],\n",
    "                      [0, 10, 0],\n",
    "                      [0, 0, 10],\n",
    "                      [0, 0, 10]], dtype=torch.float32)  # (4, 3)\n",
    "\n",
    "temp_v = torch.tensor([[1, 0],\n",
    "                      [10, 0],\n",
    "                      [100, 5],\n",
    "                      [1000, 6]], dtype=torch.float32)  # (4, 2)\n",
    "\n",
    "# This `query` aligns with the second `key`,\n",
    "# so the second `value` is returned.\n",
    "temp_q = torch.tensor([[0, 10, 0]], dtype=torch.float32)  # (1, 3)\n",
    "print_out(temp_q, temp_k, temp_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights are:\n",
      "tensor([[5.0000e-01, 5.0000e-01, 4.2166e-26, 4.2166e-26]])\n",
      "Output is:\n",
      "tensor([[5.5000e+00, 4.6383e-25]])\n"
     ]
    }
   ],
   "source": [
    "temp_q = torch.tensor([[10, 10, 0]], dtype=torch.float32)  # (1, 3)\n",
    "print_out(temp_q, temp_k, temp_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights are:\n",
      "tensor([[4.2166e-26, 4.2166e-26, 5.0000e-01, 5.0000e-01],\n",
      "        [8.4333e-26, 1.0000e+00, 8.4333e-26, 8.4333e-26],\n",
      "        [5.0000e-01, 5.0000e-01, 4.2166e-26, 4.2166e-26]])\n",
      "Output is:\n",
      "tensor([[5.5000e+02, 5.5000e+00],\n",
      "        [1.0000e+01, 9.2766e-25],\n",
      "        [5.5000e+00, 4.6383e-25]])\n"
     ]
    }
   ],
   "source": [
    "temp_q = torch.tensor([[0, 0, 10],\n",
    "                      [0, 10, 0],\n",
    "                      [10, 10, 0]], dtype=torch.float32)  # (3, 3)\n",
    "print_out(temp_q, temp_k, temp_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        assert d_model % self.num_heads == 0\n",
    "\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        self.wq = nn.Linear(d_model, d_model)\n",
    "        self.wk = nn.Linear(d_model, d_model)\n",
    "        self.wv = nn.Linear(d_model, d_model)\n",
    "\n",
    "        self.wo = nn.Linear(d_model, d_model)\n",
    "        \n",
    "    def forward(self, v, k, q, mask):\n",
    "        batch_size = q.size()[0]\n",
    "        \n",
    "        q = self.wq(q).view(batch_size, -1, self.num_heads, self.depth).transpose(1, 2)\n",
    "        k = self.wk(k).view(batch_size, -1, self.num_heads, self.depth).transpose(1, 2)\n",
    "        v = self.wv(v).view(batch_size, -1, self.num_heads, self.depth).transpose(1, 2)\n",
    "        \n",
    "        # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
    "        # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "        scaled_attention, attention_weights = scaled_dot_product_attention(q, k, v, mask)\n",
    "        \n",
    "        scaled_attention = scaled_attention.transpose(1,2).contiguous().view(batch_size, -1, self.num_heads * self.depth)\n",
    "                \n",
    "        output = self.wo(scaled_attention)  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "        return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 60, 512]), torch.Size([1, 8, 60, 60]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_mha = MultiHeadAttention(d_model=512, num_heads=8)\n",
    "y = torch.rand(1, 60, 512)  # (batch_size, encoder_sequence, d_model)\n",
    "out, attn = temp_mha(y, k=y, q=y, mask=None)\n",
    "out.shape, attn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFN(nn.Module):\n",
    "    def __init__(self, d_model, dff):\n",
    "        super(FFN, self).__init__()\n",
    "        self.layer1 = nn.Linear(d_model, dff)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.fc = nn.Linear(dff, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, dff, maximum_position_encoding, rate=0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = FFN(d_model, dff)\n",
    "        \n",
    "        self.layernorm1 = nn.LayerNorm([maximum_position_encoding, d_model])\n",
    "        self.layernorm2 = nn.LayerNorm([maximum_position_encoding, d_model])\n",
    "        \n",
    "        self.dropout1 = nn.Dropout(rate)\n",
    "        self.dropout2 = nn.Dropout(rate)\n",
    "\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
    "        attn_output = self.dropout1(attn_output)\n",
    "        out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
    "        ffn_output = self.dropout2(ffn_output)\n",
    "        out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        return out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, dff, maximum_position_encoding, rate=0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
    "        self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
    "        \n",
    "        self.ffn = FFN(d_model, dff)\n",
    "        \n",
    "        self.dropout1 = nn.Dropout(rate)\n",
    "        self.dropout2 = nn.Dropout(rate)\n",
    "        self.dropout3 = nn.Dropout(rate)\n",
    "        \n",
    "        self.layernorms1 = nn.ModuleList([copy.deepcopy(nn.LayerNorm([i+1, d_model])) for i in range(maximum_position_encoding)])\n",
    "        self.layernorms2 = nn.ModuleList([copy.deepcopy(nn.LayerNorm([i+1, d_model])) for i in range(maximum_position_encoding)])\n",
    "        self.layernorms3 = nn.ModuleList([copy.deepcopy(nn.LayerNorm([i+1, d_model])) for i in range(maximum_position_encoding)])\n",
    "\n",
    "    def forward(self, x, enc_output, look_ahead_mask, padding_mask):\n",
    "        # enc_output.shape == (batch_size, input_seq_len, d_model)\n",
    "        attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)  # (batch_size, target_seq_len, d_model)\n",
    "        attn1 = self.dropout1(attn1)\n",
    "        out1 = self.layernorms1[x.size(1)-1](attn1 + x)\n",
    "        \n",
    "        attn2, attn_weights_block2 = self.mha2(enc_output, enc_output, out1, padding_mask)  # (batch_size, target_seq_len, d_model)\n",
    "        attn2 = self.dropout2(attn2)\n",
    "        out2 = self.layernorms2[x.size(1)-1](attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
    "        \n",
    "        ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
    "        ffn_output = self.dropout3(ffn_output)\n",
    "        out3 = self.layernorms3[x.size(1)-1](ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
    "        \n",
    "        return out3, attn_weights_block1, attn_weights_block2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clones(module, N):\n",
    "    return nn.ModuleList([copy.deepcopy(module) for i in range(N)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, maximum_position_encoding, device, rate=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(input_vocab_size, d_model)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model).to(device)\n",
    "        \n",
    "        self.dec_layers = clones(EncoderLayer(d_model, num_heads, dff, maximum_position_encoding, rate), num_layers)\n",
    "        self.dropout = nn.Dropout(rate)\n",
    "\n",
    "    def forward(self, x, mask, enc_output=None):\n",
    "        if enc_output == None:\n",
    "            seq_len = x.size()[1]\n",
    "            attention_weights = {}\n",
    "            x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
    "            x *= torch.sqrt(torch.tensor(self.d_model, dtype=torch.float32))\n",
    "            x += self.pos_encoding[:, :seq_len, :]\n",
    "            x = self.dropout(x)\n",
    "            for i in range(self.num_layers):\n",
    "                x = self.dec_layers[i](x, mask)\n",
    "        else:\n",
    "            x = enc_output\n",
    "            \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size, maximum_position_encoding, device, rate=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(target_vocab_size, d_model)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model).to(device)\n",
    "        \n",
    "        self.dec_layers = clones(DecoderLayer(d_model, num_heads, dff, maximum_position_encoding, rate), num_layers)\n",
    "        self.dropout = nn.Dropout(rate)\n",
    "        \n",
    "    def forward(self, x, enc_output, look_ahead_mask, padding_mask):\n",
    "        seq_len = x.size()[1]\n",
    "        attention_weights = {}\n",
    "        x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
    "        x *= torch.sqrt(torch.tensor(self.d_model, dtype=torch.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        for i in range(self.num_layers):\n",
    "            x, block1, block2 = self.dec_layers[i](x, enc_output, look_ahead_mask, padding_mask)\n",
    "\n",
    "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
    "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
    "            \n",
    "        # x.shape == (batch_size, target_seq_len, d_model)\n",
    "        return x, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
    "               target_vocab_size, pe_input, pe_target, device, rate=0.1):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.encoder = Encoder(num_layers, d_model, num_heads, dff,\n",
    "                                 input_vocab_size, pe_input, device, rate)\n",
    "\n",
    "        self.decoder = Decoder(num_layers, d_model, num_heads, dff,\n",
    "                               target_vocab_size, pe_target, device, rate)\n",
    "\n",
    "        self.final_layer = nn.Linear(d_model, target_vocab_size)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        inp, tar, enc_output = inputs\n",
    "\n",
    "        enc_padding_mask, look_ahead_mask, dec_padding_mask = self.create_masks(inp, tar)\n",
    "\n",
    "        enc_output = self.encoder(inp, enc_padding_mask, enc_output)  # (batch_size, inp_seq_len, d_model)\n",
    "\n",
    "        # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
    "        dec_output, attention_weights = self.decoder(\n",
    "            tar, enc_output, look_ahead_mask, dec_padding_mask)\n",
    "\n",
    "        final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
    "\n",
    "        return final_output, attention_weights, enc_output\n",
    "\n",
    "    def create_masks(self, inp, tar):\n",
    "        # Encoder padding mask\n",
    "        enc_padding_mask = create_padding_mask(inp)\n",
    "\n",
    "        # Used in the 2nd attention block in the decoder.\n",
    "        # This padding mask is used to mask the encoder outputs.\n",
    "        dec_padding_mask = create_padding_mask(inp)\n",
    "\n",
    "        # Used in the 1st attention block in the decoder.\n",
    "        # It is used to pad and mask future tokens in the input received by\n",
    "        # the decoder.\n",
    "        look_ahead_mask = create_look_ahead_mask(tar.size(1))\n",
    "        dec_target_padding_mask = create_padding_mask(tar)\n",
    "        look_ahead_mask = torch.maximum(dec_target_padding_mask.to(self.device), look_ahead_mask.to(self.device))\n",
    "\n",
    "        return enc_padding_mask, look_ahead_mask, dec_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = Transformer(\n",
    "    num_layers=num_layers,\n",
    "    d_model=d_model,\n",
    "    num_heads=num_heads,\n",
    "    dff=dff,\n",
    "    input_vocab_size=input_vocab_size,\n",
    "    target_vocab_size=target_vocab_size,\n",
    "    pe_input=encoder_len,\n",
    "    pe_target=decoder_len-1,\n",
    "    device=device,\n",
    "    rate=dropout_rate\n",
    ")\n",
    "\n",
    "transformer = transformer.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 옵티마이저, 손실함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(transformer.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 손실함수 및 평가함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(real, pred):\n",
    "    mask = torch.logical_not(torch.eq(real, 0))\n",
    "    loss_ = criterion(pred.permute(0,2,1), real)\n",
    "    mask = torch.tensor(mask, dtype=loss_.dtype)\n",
    "    loss_ = mask * loss_\n",
    "\n",
    "    return torch.sum(loss_)/torch.sum(mask)\n",
    "\n",
    "def accuracy_function(real, pred):\n",
    "    accuracies = torch.eq(real, torch.argmax(pred, dim=2))\n",
    "    mask = torch.logical_not(torch.eq(real, 0))\n",
    "    accuracies = torch.logical_and(mask, accuracies)\n",
    "    accuracies = torch.tensor(accuracies, dtype=torch.float32)\n",
    "    mask = torch.tensor(mask, dtype=torch.float32)\n",
    "    \n",
    "    return torch.sum(accuracies)/torch.sum(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(batch_item, epoch, batch, training):\n",
    "    src = batch_item['src_token'].to(device)\n",
    "    tar = batch_item['tar_token'].to(device)\n",
    "    \n",
    "    tar_inp = tar[:, :-1]\n",
    "    tar_real = tar[:, 1:]\n",
    "    \n",
    "    if training is True:\n",
    "        transformer.train()\n",
    "        optimizer.zero_grad()\n",
    "        with torch.cuda.amp.autocast():\n",
    "            output, _, _ = transformer([src, tar_inp, None])\n",
    "            loss = loss_function(tar_real, output)\n",
    "        acc = accuracy_function(tar_real, output)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr = optimizer.param_groups[0][\"lr\"]\n",
    "        return loss, acc, round(lr, 10)\n",
    "    else:\n",
    "        transformer.eval()\n",
    "        with torch.no_grad():\n",
    "            output, _, _ = transformer([src, tar_inp, None])\n",
    "            loss = loss_function(tar_real, output)\n",
    "        acc = accuracy_function(tar_real, output)\n",
    "        return loss, acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "88it [00:51,  1.69it/s, Epoch=1, LR=0.0001, Loss=2.995112, Total Loss=3.973957, Total ACC=0.161590]\n",
      "7it [00:01,  5.33it/s, Epoch=1, Val Loss=6.531826, Total Val Loss=3.132918, Total Val ACC=0.325265]\n",
      "88it [00:50,  1.73it/s, Epoch=2, LR=0.0001, Loss=3.219058, Total Loss=2.485515, Total ACC=0.404288]\n",
      "7it [00:01,  5.30it/s, Epoch=2, Val Loss=6.130624, Total Val Loss=2.616009, Total Val ACC=0.428606]\n",
      "88it [00:50,  1.73it/s, Epoch=3, LR=0.0001, Loss=1.154062, Total Loss=2.091718, Total ACC=0.472268]\n",
      "7it [00:01,  5.36it/s, Epoch=3, Val Loss=5.908461, Total Val Loss=2.408663, Total Val ACC=0.468581]\n",
      "88it [00:50,  1.73it/s, Epoch=4, LR=0.0001, Loss=0.719258, Total Loss=1.880263, Total ACC=0.509830]\n",
      "7it [00:01,  5.29it/s, Epoch=4, Val Loss=5.801373, Total Val Loss=2.280617, Total Val ACC=0.486156]\n",
      "88it [00:50,  1.73it/s, Epoch=5, LR=0.0001, Loss=1.139126, Total Loss=1.735786, Total ACC=0.534228]\n",
      "7it [00:01,  5.32it/s, Epoch=5, Val Loss=5.699296, Total Val Loss=2.198627, Total Val ACC=0.505235]\n",
      "88it [00:50,  1.73it/s, Epoch=6, LR=0.0001, Loss=0.831885, Total Loss=1.618634, Total ACC=0.556863]\n",
      "7it [00:01,  5.36it/s, Epoch=6, Val Loss=5.622938, Total Val Loss=2.135514, Total Val ACC=0.516488]\n",
      "88it [00:50,  1.73it/s, Epoch=7, LR=0.0001, Loss=1.734777, Total Loss=1.530981, Total ACC=0.572242]\n",
      "7it [00:01,  5.26it/s, Epoch=7, Val Loss=5.542669, Total Val Loss=2.075320, Total Val ACC=0.533749]\n",
      "88it [00:50,  1.73it/s, Epoch=8, LR=0.0001, Loss=1.188550, Total Loss=1.437171, Total ACC=0.592122]\n",
      "7it [00:01,  5.23it/s, Epoch=8, Val Loss=5.557681, Total Val Loss=2.044987, Total Val ACC=0.537795]\n",
      "88it [00:51,  1.72it/s, Epoch=9, LR=0.0001, Loss=1.369280, Total Loss=1.354906, Total ACC=0.607646]\n",
      "7it [00:01,  5.19it/s, Epoch=9, Val Loss=5.515209, Total Val Loss=2.012759, Total Val ACC=0.540850]\n",
      "88it [00:51,  1.72it/s, Epoch=10, LR=0.0001, Loss=1.200359, Total Loss=1.281498, Total ACC=0.620244]\n",
      "7it [00:01,  5.34it/s, Epoch=10, Val Loss=5.458309, Total Val Loss=1.982638, Total Val ACC=0.548296]\n",
      "88it [00:51,  1.72it/s, Epoch=11, LR=0.0001, Loss=1.528033, Total Loss=1.214059, Total ACC=0.635175]\n",
      "7it [00:01,  5.34it/s, Epoch=11, Val Loss=5.453920, Total Val Loss=1.964951, Total Val ACC=0.555480]\n",
      "88it [00:51,  1.71it/s, Epoch=12, LR=0.0001, Loss=1.359021, Total Loss=1.145757, Total ACC=0.649700]\n",
      "7it [00:01,  5.35it/s, Epoch=12, Val Loss=5.468809, Total Val Loss=1.955149, Total Val ACC=0.558164]\n",
      "88it [00:51,  1.71it/s, Epoch=13, LR=0.0001, Loss=1.050960, Total Loss=1.074740, Total ACC=0.663672]\n",
      "7it [00:01,  5.46it/s, Epoch=13, Val Loss=5.503343, Total Val Loss=1.950397, Total Val ACC=0.559451]\n",
      "88it [00:49,  1.77it/s, Epoch=14, LR=0.0001, Loss=0.781347, Total Loss=1.013002, Total ACC=0.678776]\n",
      "7it [00:01,  5.44it/s, Epoch=14, Val Loss=5.486182, Total Val Loss=1.939833, Total Val ACC=0.561954]\n",
      "88it [00:50,  1.76it/s, Epoch=15, LR=0.0001, Loss=1.361699, Total Loss=0.959327, Total ACC=0.692934]\n",
      "7it [00:01,  5.48it/s, Epoch=15, Val Loss=5.488651, Total Val Loss=1.929595, Total Val ACC=0.568130]\n",
      "88it [00:49,  1.76it/s, Epoch=16, LR=0.0001, Loss=1.116481, Total Loss=0.894800, Total ACC=0.709325]\n",
      "7it [00:01,  5.42it/s, Epoch=16, Val Loss=5.533751, Total Val Loss=1.934840, Total Val ACC=0.573752]\n",
      "88it [00:49,  1.77it/s, Epoch=17, LR=0.0001, Loss=0.301412, Total Loss=0.832051, Total ACC=0.726313]\n",
      "7it [00:01,  5.50it/s, Epoch=17, Val Loss=5.617434, Total Val Loss=1.941689, Total Val ACC=0.574955]\n",
      "88it [00:50,  1.75it/s, Epoch=18, LR=0.0001, Loss=1.377279, Total Loss=0.789202, Total ACC=0.739280]\n",
      "7it [00:01,  5.41it/s, Epoch=18, Val Loss=5.669744, Total Val Loss=1.953536, Total Val ACC=0.572209]\n",
      "88it [00:50,  1.76it/s, Epoch=19, LR=0.0001, Loss=0.551397, Total Loss=0.726913, Total ACC=0.755101]\n",
      "7it [00:01,  5.45it/s, Epoch=19, Val Loss=5.637612, Total Val Loss=1.949150, Total Val ACC=0.577628]\n",
      "88it [00:49,  1.77it/s, Epoch=20, LR=0.0001, Loss=0.605643, Total Loss=0.678707, Total ACC=0.770762]\n",
      "7it [00:01,  5.52it/s, Epoch=20, Val Loss=5.733053, Total Val Loss=1.958436, Total Val ACC=0.576978]\n"
     ]
    }
   ],
   "source": [
    "loss_plot, val_loss_plot = [], []\n",
    "acc_plot, val_acc_plot = [], []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    gc.collect()\n",
    "    total_loss, total_val_loss = 0, 0\n",
    "    total_acc, total_val_acc = 0, 0\n",
    "    \n",
    "    tqdm_dataset = tqdm(enumerate(train_dataloader))\n",
    "    training = True\n",
    "    for batch, batch_item in tqdm_dataset:\n",
    "        batch_loss, batch_acc, lr = train_step(batch_item, epoch, batch, training)\n",
    "        total_loss += batch_loss\n",
    "        total_acc += batch_acc\n",
    "        \n",
    "        tqdm_dataset.set_postfix({\n",
    "            'Epoch': epoch + 1,\n",
    "            'LR' : lr,\n",
    "            'Loss': '{:06f}'.format(batch_loss.item()),\n",
    "            'Total Loss' : '{:06f}'.format(total_loss/(batch+1)),\n",
    "            'Total ACC' : '{:06f}'.format(total_acc/(batch+1))\n",
    "        })\n",
    "    loss_plot.append(total_loss/(batch+1))\n",
    "    acc_plot.append(total_acc/(batch+1))\n",
    "    \n",
    "    tqdm_dataset = tqdm(enumerate(val_dataloader))\n",
    "    training = False\n",
    "    for batch, batch_item in tqdm_dataset:\n",
    "        batch_loss, batch_acc = train_step(batch_item, epoch, batch, training)\n",
    "        total_val_loss += batch_loss\n",
    "        total_val_acc += batch_acc\n",
    "        \n",
    "        tqdm_dataset.set_postfix({\n",
    "            'Epoch': epoch + 1,\n",
    "            'Val Loss': '{:06f}'.format(batch_loss.item()),\n",
    "            'Total Val Loss' : '{:06f}'.format(total_val_loss/(batch+1)),\n",
    "            'Total Val ACC' : '{:06f}'.format(total_val_acc/(batch+1))\n",
    "        })\n",
    "    val_loss_plot.append(total_val_loss/(batch+1))\n",
    "    val_acc_plot.append(total_val_acc/(batch+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'cpu'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_19119/1943252761.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_plot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train_loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loss_plot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'cpu'"
     ]
    }
   ],
   "source": [
    "plt.plot(loss_plot.cpu(), label='train_loss')\n",
    "plt.plot(val_loss_plot.cpu(), label='val_loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(acc_plot, label='train_acc')\n",
    "plt.plot(val_acc_plot, label='val_acc')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('acc')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(tokens):\n",
    "    transformer.to(device)\n",
    "    decoder_input = torch.tensor([tar_tokenizer.txt2idx['sos_']] * tokens.size(0), dtype=torch.long).to(device)\n",
    "    output = decoder_input.unsqueeze(1).to(device)\n",
    "    enc_output = None\n",
    "    for i in range(decoder_len-1):        \n",
    "        # predictions.shape == (batch_size, seq_len, vocab_size)\n",
    "        with torch.no_grad():\n",
    "            predictions, attention_weights, enc_output = transformer([tokens, output, enc_output])\n",
    "        \n",
    "        # select the last token from the seq_len dimension\n",
    "        predictions_ = predictions[: ,-1:, :]  # (batch_size, 1, vocab_size)\n",
    "        \n",
    "        predicted_id = torch.tensor(torch.argmax(predictions_, axis=-1), dtype=torch.int32)\n",
    "        \n",
    "        output = torch.cat([output, predicted_id], dim=-1)\n",
    "    output = output.cpu().numpy()\n",
    "    \n",
    "    summary_list = []\n",
    "    token_list = []\n",
    "    for token in output:\n",
    "        summary = tar_tokenizer.convert(token)\n",
    "        summary_list.append(summary)\n",
    "        token_list.append(token)\n",
    "    return summary_list, token_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:11,  1.64s/it]\n"
     ]
    }
   ],
   "source": [
    "tqdm_dataset = tqdm(enumerate(val_dataloader))\n",
    "preds = []\n",
    "tokens = []\n",
    "for batch, batch_item in tqdm_dataset:\n",
    "    output = evaluate(batch_item['src_token'].to(device))\n",
    "    preds.extend(output[0])\n",
    "    tokens.extend(output[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정답 : 음성군 경로당 지원 조례 일부개정조례안은 경로당 이용에 대한 여건 및 특수성에 따라 기존 미등록 경로당 등록기준을 완화하고, 경로당 양곡 지원에 대한 근거를 마련하는 등 경로당 이용 어르신들의 건강증진 및 복지향상에 기여하기 위해 개정함. 해당 안건은 가결되었음.\n",
      "예측 :  음성군 기업 및 투자 유치 촉진 조례 일부 개정 조례 안은 < 기업 활동 촉진 조례 >에 따라 기업 활동 촉진 및 지원에 관한 법률 > 개정으로 < 음성군 기업 활동 촉진 조례 >에 관한 조례를 지원 근거를 마련하여 음성\n",
      "=================================================================================\n",
      "정답 : 음성군 군세 징수 조례 일부개정조례안과 2019년 재산세 도시지역분 적용대상 지역 고시안은 <음성군 행정기구 설치 조례>가 2019년 1월 1일 전부개정됨에 따라 변경된 사항을 조례에 반영하기 위해 제정함. 해당 안건은 가결되었음.\n",
      "예측 :  음성군 의회 공인 조례 일부 개정 조례 안은 < 지방 자치 법 > 개정에 따라 상위 법령의조례로 정하도록 위임된 사항을 반영하고 < 지방 자치 단체에 관한 사항을 반영하여 음성군 건축 조례에 반영하고\n",
      "=================================================================================\n",
      "정답 : 음성군 폐기물 관리 조례 일부개정조례안은 쓰레기처리비 대비 수수료 수입비율인 주민부담율이 낮아 청소행정의 건전 재정을 저해하고 불법반입 폐기물이 증가하는 문제가 있어 지역 실정에 맞도록 쓰레기 종량제 수수료를 조정하고자 제정함. 해당 안건은 가결 되었음.\n",
      "예측 :  음성군 의회 사무 분장 규칙 일부 개정 규칙 안은 상위 법에 따른 음성군 도로 명 주소 등의조례에 따른 음성군 도로 명 주소 등으로 인한 수수료를 조례에 맞게 개정하여 음성군 도로 명 주소에 따른 음성군 도로 명 주\n",
      "=================================================================================\n",
      "정답 : 음성군 농업기계 사후관리 출장비용 지원 조례안은 음성군 농업인의 농업생산성 향상과 경영 개선, 기계화 영농 편의 등을 제공하고 농업기계 안전사용을 도모하기 위해 제정함. 해당 안건은 가결되었음.\n",
      "예측 :  음성군 학교 지원 조례 안은 독립 유공자의건강 증진과 지역 경제 활성 화 및 지원을 위한 지원하여 지역 경제 활성 화를 도모하고자 제정함. 해당 안건은 가결됨.\n",
      "=================================================================================\n",
      "정답 : 일반농산어촌개발사업 공유재산 시설물 관리위탁 운영 동의안은 조성한 시설물의 효율적인 관리를 위해 추진위원회에 그 재산의 관리를 위탁하고자 하는 것에 동의를 구하기 위해 발의됨. 해당 안건은 가결되었음.\n",
      "예측 :  음성군 공유 재산 관리 계획 변경 계획안은 지방 재정법 시행령의위원회의위원회 구성과 재산과 재산과 재산과 재산 취득 , 공유 재산 취득 계획을 위한 사업의심의를 위한 사업의취득 및 재 활용을 위한 사업의취득 \n",
      "=================================================================================\n",
      "정답 : 제251회 음성군의회 제2차 정례회 제3차 본회의 개의.\n",
      "예측 :  음성군 의회 회의 음성군 의회 회의 규칙 안은 음성군 의회 회의 규칙의회의 음성군 의회 회의 규칙을 제 3 차 정례회 제 3 차 본회의개의선포 . 제 3 차 본회의의원으로부터 소집 요구가 있어 3 차 정례회 \n",
      "=================================================================================\n",
      "정답 : 2014년도 세입 세출예산안이 가결됨. 2014년도 기금운용계획안이 가결됨.\n",
      "예측 :  2013 년도 세입 , 세출 예산안 승인의건이 각각 가결됨 . 2013 년도 기금 운용 계획안 승인의건은 각각 가결됨 . 2013 년도 기금 운용 계획안 승인의건은 심사 결과 가결됨.\n",
      "=================================================================================\n",
      "정답 : 2013~2017년도 음성군 중기지방재정계획 보고. 분야별 세부사업 계획 속에 현재 진행되고 있는 사업의 보고가 누락된 부분을 시정할 것.\n",
      "예측 :  음성군 의회 의원 의정 활동비 등 지급에 관한 조례 안은 지방 자치 단체의회의의회의 의결을 지급하여 음성군의회의 의결을 받아 주기 위해 제안함. 해당 안건은 가결됨.\n",
      "=================================================================================\n",
      "정답 : 음성군 행정기구 설치 조례 일부개정조례안은 각종 시설물과 조직을 효율적으로 관리하고자 제정되었으며, 해당 안건은 가결됨. 음성군 지방공무원 정원 조례 일부개정조례안은 총액인건비 기준 정원으로 정원을 감축함으로써 신규사업 등에 따른 각종 페널티를 방지하고 기능직 등을 일반직으로 직종 개편하고자 제안함.\n",
      "예측 :  음성군 지방 공무원 정원 조례 일부 개정 조례 안은 < 지방 공무원 수당 등에 관한 법률 > 제 4 조에 의거 행정 기구 설치 조의규정에 의거 행정 기구 설치 조례의규정에 의거 행정 기구 설치 조례를 개정하고자 제\n",
      "=================================================================================\n",
      "정답 : 음성군 건축 조례 일부개정조례안은 법령에서 조례로 위임된 사무에 대하여 제도시행에 필요한 사항을 자치 실정에 맞도록 건축조례 일부를 개정하고자 제정되었으며, 해당 안건은 가결됨.\n",
      "예측 :  음성군 건축 조례 일부 개정 조례 안은 < 건축법 > 개정에 따라 법령에서 위임된 사항을 반영하고 < 지방세 기본법 > 개정에 맞게 조례에 맞게 정비 및 보완 사항을 반영하여 음성군 건축 규제 완화하고\n",
      "=================================================================================\n",
      "정답 : 12월 17일부터 12월 19일까지 휴회가 가결됨. 제4차 본회의는 12월 20일 오전 10시에 개의.\n",
      "예측 :  12 월 20 일부터 12 월 21 일까지 3 일 간 휴회가 가결됨 . 제 3 차 본회의는 12 월 21 일 오전 10 시에 개의.\n",
      "=================================================================================\n"
     ]
    }
   ],
   "source": [
    "for i, (a, p) in enumerate(zip(df_val.summary, preds)):\n",
    "    print('정답 :', a)\n",
    "    print('예측 :', p)\n",
    "    print('=================================================================================')\n",
    "    if i == 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 제출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16it [00:27,  1.74s/it]\n"
     ]
    }
   ],
   "source": [
    "tqdm_dataset = tqdm(enumerate(test_dataloader))\n",
    "preds = []\n",
    "tokens = []\n",
    "for batch, batch_item in tqdm_dataset:\n",
    "    output = evaluate(batch_item['src_token'].to(device))\n",
    "    preds.extend(output[0])\n",
    "    tokens.extend(output[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['summary'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_2000-AGENDA_1</td>\n",
       "      <td>음성군 의회 회의 규칙 일부 개정 규칙 안은 음성군 의회 회의 규칙의회의 규칙의회...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_2000-AGENDA_2</td>\n",
       "      <td>음성군 의회 정례회의운영에 관한 조례 안은 음성군의회의의회의의회의의회의의회의의회의...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_2000-AGENDA_3</td>\n",
       "      <td>음성군 의회 제 1 차 정례회 회의록 서명 의원으로 반광홍 의원 , 김윤희 의원이...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_2000-AGENDA_4</td>\n",
       "      <td>예산 결산 특별 위원회는 한동완 의원 , 우성 수 의원 , 이상정 의원 , 이상정...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_2000-AGENDA_5</td>\n",
       "      <td>음성군 주요 사업 현지 확인 특별 위원회 구성 결의안은 음성군의위원회 구성과 지역...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                uid                                            summary\n",
       "0  id_2000-AGENDA_1   음성군 의회 회의 규칙 일부 개정 규칙 안은 음성군 의회 회의 규칙의회의 규칙의회...\n",
       "1  id_2000-AGENDA_2   음성군 의회 정례회의운영에 관한 조례 안은 음성군의회의의회의의회의의회의의회의의회의...\n",
       "2  id_2000-AGENDA_3   음성군 의회 제 1 차 정례회 회의록 서명 의원으로 반광홍 의원 , 김윤희 의원이...\n",
       "3  id_2000-AGENDA_4   예산 결산 특별 위원회는 한동완 의원 , 우성 수 의원 , 이상정 의원 , 이상정...\n",
       "4  id_2000-AGENDA_5   음성군 주요 사업 현지 확인 특별 위원회 구성 결의안은 음성군의위원회 구성과 지역..."
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('dacon_baseline.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "제출 API 사용법 => https://dacon.io/forum/403557"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dacon_submit_api import dacon_submit_api \n",
    "\n",
    "# result = dacon_submit_api.post_submission_file(\n",
    "#     'dacon_baseline.csv', \n",
    "#     '개인 Token', \n",
    "#     '235813',\n",
    "#     'BASELINE', \n",
    "#     'DACON_Baseline'\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f7c518d4530874c5067e4cd9b290fec41a29d6e8ac13b488d5e59750ed4bc0f4"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('yunihg': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
